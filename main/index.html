<p><!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>洗衣液价格比较</title>
  </p>
<style>
    body { font-family: Arial, sans-serif; margin: 20px; }
    .article { margin-bottom: 40px; }
    .title { font-size: 24px; margin-bottom: 10px; }
    .content { line-height: 1.6; }
  </style>
<p></head>
<body>
  </p>
<h1>价格比较</h1>
<ul>
        <li>
          <h2><a href="https://blog.langchain.dev/customers-webtoon/">How Webtoon Entertainment built agentic workflows with LangGraph to scale story understanding</a></h2>
          <p># Webtoon Entertainment 使用 LangGraph 构建叙事理解 AI

**Webtoon Entertainment** 是全球数字娱乐公司，以其垂直滚动漫画格式和两大平台 **WEBTOON** 与 **Wattpad** 闻名。为应对海量内容处理需求，Webtoon 开发了 **Webtoon Comprehension AI (WCAI)**，利用 LangGraph 的多智能体工作流实现叙事理解的规模化。

## 核心功能
WCAI 支持多个团队（如营销、翻译、推荐）通过自然语言查询获取即时洞察，包括角色分析、情节总结等。其核心工作流包括：
1. **角色识别**：提取角色名称、角色关系及代表性图像。
2. **说话人识别**：结合视觉语言模型分析对话气泡并匹配角色。
3. **叙事提取**：生成结构化剧情摘要，捕捉关键情节和情感节点。
4. **业务洞察生成**：基于用户意图提供高价值输出，例如营销主题匹配或推荐场景提取。

## 技术架构
WCAI 基于 LangGraph 的模块化节点架构，结合视觉语言模型（VLMs）和领域专家知识，支持动态路由和高效调试。LangGraph 因其可控性、透明性和生产级部署能力成为首选框架。

## 成果与未来
- 自动化叙事理解使内容团队工作量减少 70%，显著提升生产力。
- 未来计划包括系统化评估、更精细的人机交互控制以及外部数据源整合。

通过 WCAI 和 LangGraph，Webtoon 正推动叙事理解的规模化创新，赋能团队创造力，释放 IP 潜力。</p>
        </li>
        <li>
          <h2><a href="https://blog.langchain.dev/langsmith-alerts/">Catch production failures early with LangSmith Alerts</a></h2>
          <p># LangSmith Alerts：提前捕获生产故障

可靠的应用程序是优质用户体验的基础，而提前捕获故障则是关键。LangSmith 推出了 **Alerts** 功能，帮助开发者实时监控 LLM 应用和代理的表现。

### 核心功能
支持基于以下指标设置告警：
1. **错误率**
2. **运行延迟**
3. **反馈评分**

通过过滤器可针对特定运行子集（如模型、工具调用类型）设置告警，并支持 5 或 15 分钟的聚合窗口和阈值调整。告警可通过 PagerDuty 或自定义 Webhook 集成到现有工作流中（如 Slack 通知）。

### 为什么主动监控重要？
1. **依赖外部服务**：LLM 应用依赖多个外部服务（如 API、数据库等），任何中断或延迟都会影响体验。
2. **质量与正确性**：LLM 输出的质量可能因提示、模型或输入变化而波动，反馈评分告警可快速发现质量问题。

### 未来计划
- 新增告警类型：运行计数、LLM Token 使用量。
- 支持相对值变化告警（如延迟增加 25%）。
- 自定义时间窗口。

[立即开始使用 LangSmith Alerts](https://docs.smith.langchain.com/observability/how_to_guides/alerts?ref=blog.langchain.dev) 并通过 [LangChain Slack 社区](https://langchaincommunity.slack.com/?ref=blog.langchain.dev) 提供反馈！</p>
        </li>
        <li>
          <h2><a href="https://blog.langchain.dev/customers-trellix/">How Trellix cut log parsing time from days to minutes with LangGraph Studio and LangSmith</a></h2>
          <p># Trellix 使用 LangGraph 和 LangSmith 提升日志解析效率

**背景**: Trellix 是一家领先的网络安全公司，致力于保护企业免受网络攻击。面对日益增长的客户请求积压和日志解析挑战，Trellix 开发了内部应用 Sidekick，通过自动化流程显著提高效率。

**问题**: 客户请求处理和日志解析耗时过长（2-3天），导致客户不满和工程师负担加重。

**解决方案**: 
- **Sidekick 平台**: 利用 LangSmith 和 LangGraph Studio，实现了日志自动解析和插件开发。
- **LangGraph 优势**: 提供模块化工具和低级抽象功能，简化了复杂任务的开发流程。
- **可视化与监控**: LangGraph Studio 帮助可视化工作流，LangSmith 用于性能监控和数据驱动决策。

**成果**:
- 日志解析时间从**数天缩短到数分钟**。
- 加速客户请求处理，减少积压。
- 提高 AI 模型透明度，增强非技术利益相关者的信任。

**未来计划**: 扩展 Sidekick 功能至外部合作伙伴，进一步推动 AI 驱动的网络安全解决方案。

**结论**: 借助 LangGraph 和 LangSmith，Trellix 显著提升了运营效率和客户满意度，为未来创新奠定了基础。</p>
        </li>
        <li>
          <h2><a href="https://blog.langchain.dev/how-to-think-about-agent-frameworks/">How to think about agent frameworks</a></h2>
          <p># 如何思考代理框架

本文探讨了构建可靠代理系统的核心挑战及不同代理框架的设计理念与功能。

## 核心观点
1. **构建可靠代理系统的难点**  
   确保大语言模型（LLM）在每一步都能获得适当的上下文，包括控制输入内容和生成相关上下文的步骤。

2. **代理系统的组成**  
   代理系统包含工作流（Workflows）和代理（Agents），以及两者的混合形式。

3. **现有框架的问题**  
   大多数代理框架并非声明式或命令式编排框架，而只是提供了一组代理抽象。这些抽象虽然易于上手，但往往掩盖了对LLM上下文的精确控制。

4. **LangGraph的特点**  
   LangGraph是一个编排框架，支持声明式和命令式API，并内置了代理抽象，适合从简单到复杂的各类应用场景。

---

## 背景信息

### 什么是代理？
- **OpenAI的定义**：代理是能够独立完成任务的系统。  
  （过于宽泛且缺乏实用性）
- **Anthropic的定义**：代理通过工具实现动态决策，而工作流则依赖预定义路径。  
  （更技术化，强调“代理系统”这一广义概念）

### 构建代理的难点
代理原型容易实现，但要构建可靠的生产级代理系统却很困难：
- 模型性能不足
- 输入上下文不完整或模糊
- 工具描述不清或响应格式不佳

核心问题在于**如何确保LLM在每一步都获得正确的上下文**。

---

## 代理框架的分类

### 工作流 vs 代理
- **工作流**：流程固定，上下文易于控制，适合高预测性场景。
- **代理**：灵活性强，但难以保证上下文的一致性，适合复杂任务。

### 声明式 vs 命令式
- LangGraph结合了声明式和命令式设计，既直观又灵活。
- 其他框架（如Agents SDK）多为抽象层，而非真正的编排框架。

### 多代理系统
复杂系统通常需要多个代理协作，关键在于它们之间的通信机制。

---

## 常见问题

### 框架的价值
框架不仅提供代理抽象，还支持以下功能：
- 短期记忆与长期记忆
- 人类参与（实时或事后干预）
- 流式更新与调试工具
- 容错与优化能力

### 模型进步是否会减少对框架的需求？
即使模型性能提升，仍需框架来处理复杂任务的上下文控制和生产需求。

### OpenAI的观点有何问题？
OpenAI的文章混淆了“声明式 vs 命令式”、“工作流 vs 代理”等维度，忽视了生产系统中上下文管理的重要性。

---

## 结论

1. 可靠代理系统的关键在于**精确控制LLM的上下文**。
2. 生产级代理系统通常是**工作流与代理的结合**。
3. LangGraph作为编排框架，提供了灵活性与控制力，适合作为构建代理系统的底层工具。

更多细节可参考[LangGraph文档](https://langchain-ai.github.io/langgraph/)及相关框架对比表格。</p>
        </li>
        <li>
          <h2><a href="https://blog.langchain.dev/customers-abu-dhabi-government/">TAMM AI Assistant: Transforming Government Services in Abu Dhabi with LangChain and LangGraph"</a></h2>
          <p># TAMM AI 助手：阿布扎比政府服务的革新  

TAMM平台是阿布扎比政府的一站式服务中心，提供940多项服务，涵盖公民、居民、游客和企业的多样化需求。2024年10月，TAMM 3.0发布，标志着人工智能全面融入其生态系统，从服务交付到日常运营均实现智能化。核心创新是基于LangChain和LangGraph构建的AI助手，具备五项关键工作流：  

1. **服务查询与信息检索**：通过RAG管道快速响应用户问题，如护照续签或天气查询。  
2. **用户特定数据交互**：根据用户历史提供个性化服务，如显示有效文件或到期提醒。  
3. **服务执行**：支持跨平台无缝完成服务，确保一致体验。  
4. **通用知识讨论**：扩展至非特定领域，回答如露营地点推荐等问题。  
5. **支持流程**：新增“拍照并报告”功能，自动提交事件详情并分配给相关部门。  

借助LangGraph的灵活性和标准化，TAMM实现了多智能体架构，展现了数字政府服务的未来方向。</p>
        </li>
  </ul>
<p></body>
</html></p>