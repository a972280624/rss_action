<p><!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>洗衣液价格比较</title>
  </p>
<style>
    body { font-family: Arial, sans-serif; margin: 20px; }
    .article { margin-bottom: 40px; }
    .title { font-size: 24px; margin-bottom: 10px; }
    .content { line-height: 1.6; }
  </style>
<p></head>
<body>
  </p>
<h1>价格比较</h1>
<ul>
        <li>
          <h2><a href="https://blog.langchain.dev/customers-webtoon/">How Webtoon Entertainment built agentic workflows with LangGraph to scale story understanding</a></h2>
          <p># Webtoon Entertainment 使用 LangGraph 构建叙事理解 AI

**Webtoon Entertainment**（纳斯达克：WBTN）是全球数字娱乐公司，以垂直滚动漫画格式闻名，运营 **WEBTOON** 和 **Wattpad** 两大平台。通过将原创 IP 改编为影视、动画等内容，Webtoon 不断推动跨媒体内容生态发展。

为应对海量内容处理需求，Webtoon 开发了 **Webtoon Comprehension AI (WCAI)**，利用 **LangGraph** 的多智能体工作流实现规模化叙事理解。WCAI 通过自然语言查询，快速生成角色分析、情节摘要和视觉/文本上下文理解，广泛应用于营销、翻译和推荐团队，显著减少手动操作（如阅读新标题提取关键词的工作量减少 70%）。

### 技术亮点
- **混合架构**：结合视觉-语言模型（VLMs）与 LangGraph 的节点化工作流。
- **核心功能**：
  1. 角色识别：构建角色档案。
  2. 对话归属：分析气泡对话并匹配角色。
  3. 叙事提取：生成结构化情节摘要。
  4. 业务洞察：提供定制化分析支持。

### 为什么选择 LangGraph？
1. **可控性**：满足生产环境对透明性和可靠性的需求。
2. **生产就绪**：轻松部署 API，借助 LangSmith 实现高效调试。

### 成果与展望
WCAI 显著提升了生产力，赋能团队专注于创意与战略任务。未来计划包括精细化人机交互、扩展外部数据集成等，持续推动叙事理解的规模化创新。</p>
        </li>
        <li>
          <h2><a href="https://blog.langchain.dev/langsmith-alerts/">Catch production failures early with LangSmith Alerts</a></h2>
          <p># 用 LangSmith Alerts 提前捕获生产故障

可靠的应用程序是优质用户体验的基础，而提前发现故障是关键。LangSmith 推出了 **Alerts** 功能，帮助开发者实时监控 LLM 应用和代理。支持基于 **错误率**、**运行延迟** 和 **反馈评分** 等关键指标设置警报。

## 为什么主动监控很重要？

1. **对外部服务的依赖**  
   LLM 应用依赖多个外部服务（如模型提供商、API、数据库等），这些服务的中断或延迟会显著影响用户体验。

2. **质量与准确性**  
   LLM 输出的质量可能因提示、模型或输入变化而不稳定，反馈评分警报可提供早期预警。

## LangSmith Alerts 概览

支持以下指标的警报：
- 错误数量和比率
- 平均延迟
- 平均反馈评分  

可通过过滤器聚焦特定运行子集，并设置聚合窗口（5 或 15 分钟）和阈值。警报可通过 PagerDuty 或自定义 Webhook 集成到现有工作流中。

[立即开始设置警报](https://docs.smith.langchain.com/observability/how_to_guides/alerts?ref=blog.langchain.dev)

## 未来计划

- 增加更多警报类型（如运行计数、LLM Token 使用量）
- 支持相对值变化警报（如延迟增加 25%）
- 自定义时间窗口警报

有建议？欢迎通过 [LangChain Slack 社区](https://langchaincommunity.slack.com/?ref=blog.langchain.dev) 联系我们！</p>
        </li>
  </ul>
<p></body>
</html></p>