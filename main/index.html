<p><!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>洗衣液价格比较</title>
  </p>
<style>
    body { font-family: Arial, sans-serif; margin: 20px; }
    .article { margin-bottom: 40px; }
    .title { font-size: 24px; margin-bottom: 10px; }
    .content { line-height: 1.6; }
  </style>
<p></head>
<body>
  </p>
<h1>价格比较</h1>
<ul>
        <li>
          <h2><a href="https://blog.langchain.dev/customers-webtoon/">How Webtoon Entertainment built agentic workflows with LangGraph to scale story understanding</a></h2>
          <p># Webtoon Entertainment 使用 LangGraph 构建叙事理解 AI

**Webtoon Entertainment**（纳斯达克代码：WBTN）是全球数字娱乐公司，以垂直滚动漫画格式闻名，运营 **WEBTOON** 和 **Wattpad** 两大平台，覆盖多种类型的内容创作。为处理海量内容，公司开发了 **Webtoon Comprehension AI (WCAI)**，利用 LangGraph 的多智能体工作流实现规模化叙事理解。

## 核心功能与技术
WCAI 基于混合架构，结合视觉语言模型（VLM）和 LangGraph 的节点式工作流，支持以下核心任务：
1. **角色识别**：提取角色名称、角色关系及代表性图像。
2. **说话人识别**：分析对话气泡并将其分配给角色。
3. **叙事提取**：生成结构化情节摘要，捕捉关键事件和情感节点。
4. **业务洞察生成**：为营销、翻译、推荐等团队提供定制化数据支持。

## 选择 LangGraph 的原因
- **可控性与透明性**：满足领域专家协作需求，确保结果可解释。
- **生产级部署**：LangGraph 提供高效的 API 集成和强大的调试能力。

## 成果与未来规划
WCAI 自动化了故事理解流程，减少了 70% 的人工工作量，并显著提升了团队效率。未来计划包括扩展工作流评估、优化人机交互，以及整合外部数据源，进一步提升叙事分析能力。</p>
        </li>
        <li>
          <h2><a href="https://blog.langchain.dev/langsmith-alerts/">Catch production failures early with LangSmith Alerts</a></h2>
          <p># 用 LangSmith Alerts 提前捕获生产故障

可靠的用户体验始于可靠的应用程序。为此，LangSmith 推出了 **Alerts** 功能，帮助开发者实时监控 LLM 应用和智能体的表现，提前发现问题。

## 核心功能
- 支持基于 **错误率**、**运行延迟** 和 **反馈评分** 设置告警。
- 可通过过滤器聚焦特定运行子集（如按模型或工具调用）。
- 支持 5 或 15 分钟的时间窗口聚合，并可集成到 PagerDuty 或自定义 Webhook（如 Slack）。

## 为什么需要主动监控？
1. **外部服务依赖**：LLM 应用依赖多个外部服务（如 API、数据库等），这些服务的中断或延迟会严重影响用户体验。
2. **输出质量与正确性**：LLM 输出可能因提示、模型或输入的变化而波动，反馈评分告警能及时捕捉质量问题。

## 未来计划
- 增加更多告警类型（如运行计数、Token 使用量）。
- 支持相对值变化告警（如延迟增加 25%）。
- 自定义时间窗口支持。

立即访问 [文档](https://docs.smith.langchain.com/observability/how_to_guides/alerts?ref=blog.langchain.dev) 开始使用！</p>
        </li>
        <li>
          <h2><a href="https://blog.langchain.dev/customers-trellix/">How Trellix cut log parsing time from days to minutes with LangGraph Studio and LangSmith</a></h2>
          <p># Trellix 使用 LangGraph 和 LangSmith 提升日志解析效率

**概述**  
Trellix 是一家领先的网络安全公司，致力于保护企业免受网络攻击。为应对客户请求积压和日志解析效率低下的问题，Trellix 开发了内部应用 Sidekick，利用 LangSmith 和 LangGraph（包括 LangGraph Studio）实现知识普及与流程自动化。

**问题背景**  
- 客户请求积压严重，日志解析耗时 2-3 天。
- 手动处理导致客户体验差、支持票反复流转。

**解决方案**  
通过 LangGraph 和 LangSmith，Sidekick 实现了：
1. **日志解析时间从天缩短到分钟**：自动生成未知日志格式的解析器。
2. **插件开发加速**：AI 代理快速生成代码，将多天任务压缩至半天。
3. **工作流可视化**：LangGraph Studio 帮助优化流程，并向非技术利益相关者清晰展示 AI 推理逻辑。
4. **性能监控**：使用 LangSmith 测试架构、跟踪关键指标（如递归率、文档检索率），提升代理性能。

**成果与影响**  
- 日志解析时间大幅缩短，工程师效率倍增。
- 客户请求积压减少，满意度提升。
- 内部调试更高效，利益相关者信心增强。

**未来计划**  
Trellix 计划将 Sidekick 的能力扩展至外部合作伙伴，进一步推动 AI 驱动的网络安全解决方案。

**结论**  
借助 LangSmith 和 LangGraph，Trellix 成功提升了运营效率和客户满意度，为 AI 在网络安全领域的应用树立了标杆。</p>
        </li>
        <li>
          <h2><a href="https://blog.langchain.dev/how-to-think-about-agent-frameworks/">How to think about agent frameworks</a></h2>
          <p># 总结：如何思考智能体框架

构建可靠的智能体系统的核心难点在于确保大语言模型（LLM）在每一步都能获得适当的上下文。这包括控制输入到LLM的内容，以及生成相关上下文的步骤。

- **智能体系统** 包括工作流（workflows）和智能体（agents），以及介于两者之间的混合形式。
- 大多数智能体框架并非声明式或命令式编排框架，而只是提供了一组智能体抽象。
- 智能体抽象虽然易于上手，但往往掩盖了对LLM上下文的精确控制，增加了构建可靠系统的难度。
- LangGraph 是一个兼具声明式和命令式 API 的编排框架，支持智能体抽象，并提供了生产所需的多种功能（如持久化、容错、人机交互等）。

### 核心挑战
构建可靠智能体的主要困难在于确保 LLM 在每一步都有正确的上下文。常见问题包括：
- 系统提示不完整或模糊
- 用户输入不明确
- 工具描述不清晰或响应格式不佳

### 框架的价值
智能体框架的价值不仅体现在高层抽象，还包括：
- 短期和长期记忆存储
- 人机交互支持（human-in-the-loop 和 human-on-the-loop）
- 流式更新与调试能力
- 容错与优化能力

### 工作流 vs 智能体
- **工作流** 更加可控且适合简单任务。
- **智能体** 提供更高灵活性，但复杂性和不可预测性也更高。
- 生产环境中的智能体系统通常是两者的结合。

### 对 OpenAI 观点的批评
OpenAI 的智能体指南存在误导，例如将“声明式 vs 命令式”与“工作流 vs 智能体”混淆，忽略了编排框架的核心价值——即精确控制 LLM 上下文的能力。

### 结论
无论是智能体还是工作流，所有形式的智能体系统都受益于一套通用的功能支持（如持久化、调试、流式处理等）。LangGraph 提供了一个灵活的编排框架，允许开发者根据需求自由选择工作流或智能体的设计模式。</p>
        </li>
        <li>
          <h2><a href="https://blog.langchain.dev/customers-abu-dhabi-government/">TAMM AI Assistant: Transforming Government Services in Abu Dhabi with LangChain and LangGraph"</a></h2>
          <p># TAMM AI 助手：阿布扎比政府服务的革新

TAMM平台是阿布扎比政府的一站式服务平台，提供940多项服务，涵盖驾驶执照申请、罚款支付和个人文件检索等。2024年10月，阿布扎比政府赋能部（DGE）在GITEX全球大会上推出了TAMM 3.0，标志着人工智能（AI）在服务交付、客户支持和日常运营中的全面应用。

## TAMM AI 助手的核心功能
基于LangChain和LangGraph构建，TAMM AI助手通过五大关键工作流优化用户体验：
1. **服务查询与信息检索**：通过RAG管道快速响应用户问题。
2. **用户特定数据交互**：根据用户历史提供个性化服务。
3. **服务执行**：跨平台无缝完成服务请求。
4. **通用知识与讨论**：支持广泛主题的智能对话。
5. **支持流程**：通过“拍照并报告”功能提升事件处理效率。

## 技术优势
借助LangChain的强大编排能力，TAMM AI助手与统一后端集成，确保实时功能和高效操作。LangGraph进一步提升了灵活性和标准化。

## 未来展望
TAMM AI助手代表了公民参与的未来，展示了DGE在数字转型领域的全球领导地位。</p>
        </li>
  </ul>
<p></body>
</html></p>