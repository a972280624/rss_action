<p><!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>洗衣液价格比较</title>
  </p>
<style>
    body { font-family: Arial, sans-serif; margin: 20px; }
    .article { margin-bottom: 40px; }
    .title { font-size: 24px; margin-bottom: 10px; }
    .content { line-height: 1.6; }
  </style>
<p></head>
<body>
  </p>
<h1>价格比较</h1>
<ul>
        <li>
          <h2><a href="https://blog.langchain.dev/customers-webtoon/">How Webtoon Entertainment built agentic workflows with LangGraph to scale story understanding</a></h2>
          <p># Webtoon Entertainment 使用 LangGraph 构建叙事理解 AI 系统

**Webtoon Entertainment**（纳斯达克：WBTN）是全球数字娱乐公司，以垂直滚动漫画格式闻名，运营 **WEBTOON** 和 **Wattpad** 两大平台，覆盖多元内容和创作者生态系统，并将其原创 IP 改编为影视作品。

为应对海量内容处理需求，Webtoon 推出了 **Webtoon Comprehension AI (WCAI)**，基于 **LangGraph** 的多智能体工作流系统。WCAI 能够大规模理解角色、叙事和图文上下文，支持营销、翻译和推荐团队通过自然语言查询获取即时洞察，减少手动操作。

### 技术亮点
- **架构**：结合视觉语言模型（VLMs）与 LangGraph 的节点化工作流。
- **核心流程**：
  1. **角色识别**：提取角色信息并构建结构化档案。
  2. **对话归属**：分析气泡对话并分配给角色。
  3. **叙事提取**：生成关键情节的文本摘要。
  4. **业务洞察**：根据团队需求生成特定见解，如关键词和高亮场景。

### 为何选择 LangGraph？
- 提供可控性、透明性和可靠性。
- 支持生产级部署，集成 LangSmith 实现高效调试与优化。

### 成果与展望
WCAI 显著提升了叙事理解效率，减少了 70% 的手动工作量。未来计划包括多场景验证、人机交互优化及外部数据整合，进一步释放 Webtoon IP 的潜力。</p>
        </li>
        <li>
          <h2><a href="https://blog.langchain.dev/langsmith-alerts/">Catch production failures early with LangSmith Alerts</a></h2>
          <p># LangSmith Alerts：提前捕获生产故障

为了打造可靠的应用程序，提前捕获故障至关重要。LangSmith 推出了 **Alerts** 功能，帮助开发者实时监控 LLM 应用和代理的表现。

## 核心功能
- 支持基于关键指标设置告警：**错误率**、**运行延迟**、**反馈评分**。
- 提供灵活过滤器，针对特定运行子集（如模型、工具调用类型）进行监控。
- 支持 5 或 15 分钟的聚合窗口，并可调整敏感度阈值。
- 集成到现有工作流中，支持通过 PagerDuty 或自定义 Webhook（如 Slack）发送通知。

## 为什么主动监控重要？
1. **外部服务依赖**：LLM 应用依赖多个外部服务（如 API、数据库）。这些依赖的中断或延迟会显著影响用户体验。
2. **输出质量与正确性**：LLM 的输出可能因提示、模型或输入变化而波动，用户反馈评分提供早期预警。

## 未来计划
- 新增更多告警类型：运行计数、LLM Token 使用量。
- 支持相对值告警（如延迟激增 25%）。
- 自定义时间窗口。

[立即开始配置告警](https://docs.smith.langchain.com/observability/how_to_guides/alerts?ref=blog.langchain.dev) 并加入 [LangChain Slack 社区](https://www.langchain.com/join-community?ref=blog.langchain.dev) 提供反馈！</p>
        </li>
        <li>
          <h2><a href="https://blog.langchain.dev/customers-trellix/">How Trellix cut log parsing time from days to minutes with LangGraph Studio and LangSmith</a></h2>
          <p># Trellix 借助 LangGraph 和 LangSmith 提升效率案例总结

Trellix 是一家领先的网络安全公司，客户超过 40,000 家。为应对日益增长的客户请求积压和日志解析问题，其专业服务团队开发了内部应用 **Sidekick**，利用 **LangSmith** 和 **LangGraph** 自动化繁琐任务。

## 核心问题与解决方案
1. **问题**：
   - 日志解析和集成请求需要工程师花费 2-3 天完成，导致客户体验差、支持票积压。
   - 插件开发依赖手动读取 API 文档并生成样板代码，耗时长。

2. **解决方案**：
   - 使用 **LangGraph** 构建模块化工作流，自动生成未知日志格式的解析器，将解析时间从 **数天缩短至分钟级**。
   - 开发智能代理加速插件开发，传统需多天完成的任务缩短至半天。

## 技术优势
- **LangGraph** 提供低级工具和抽象技术，支持高效定制化。
- **LangGraph Studio** 可视化工作流，帮助技术与非技术利益相关者理解 AI 推理过程。
- **LangSmith** 提供实验平台，通过性能指标（如递归率、关键文档检索率）优化代理架构。

## 成果与影响
- 日志解析时间大幅缩短，提升工程效率。
- 客户请求解决速度加快，减少积压。
- 内部用户满意度提高，利益相关者信心增强。

## 未来展望
Trellix 计划将 Sidekick 的能力扩展至外部合作伙伴，进一步普及 AI 驱动的网络安全解决方案，目标是下一季度覆盖所有客户。

---

**结论**：  
借助 LangSmith、LangGraph 和 LangGraph Studio，Trellix 成功解决了运营挑战，提升了内部效率和客户满意度，为未来创新奠定了基础。</p>
        </li>
        <li>
          <h2><a href="https://blog.langchain.dev/how-to-think-about-agent-frameworks/">How to think about agent frameworks</a></h2>
          <p># 关于如何思考智能体框架的总结

## 核心观点
构建可靠的智能体系统的关键在于确保大语言模型（LLM）在每一步都获得适当的上下文，包括精确控制输入内容以及生成相关内容的步骤。智能体系统既包含工作流（Workflows），也包含智能体（Agents），并且大多数实际应用是两者的结合。

## 智能体框架的分类
1. **工作流 vs 智能体**  
   - 工作流：通过预定义代码路径编排 LLM 和工具，流程更确定性。
   - 智能体：LLM 动态控制自身流程和工具使用，灵活性更高。
   - 实际生产中，大多数系统是两者的结合。

2. **声明式 vs 非声明式**  
   - 声明式框架（如 LangGraph）以图结构表示节点和边，适合复杂逻辑。
   - 非声明式框架通常是抽象的智能体类，缺乏对底层逻辑的控制。

3. **智能体抽象的优缺点**  
   - 优点：易于上手，快速构建原型。
   - 缺点：可能掩盖问题，难以确保 LLM 获得正确的上下文。

4. **多智能体系统**  
   - 多智能体之间的通信方式至关重要，通常结合工作流实现更高的可靠性。

## LangGraph 的特点
LangGraph 是一个兼具声明式和命令式 API 的编排框架，支持以下功能：
- **短时记忆与长时记忆**：支持多轮对话和跨会话记忆。
- **人机协作**：支持实时干预和事后审查（Human-in-the-loop 和 Human-on-the-loop）。
- **流式处理**：支持实时更新用户界面。
- **调试与可观测性**：集成 LangSmith 提供强大的调试和监控能力。
- **容错性**：支持持久化存储和节点重试机制。

## 常见问题
1. **框架的价值是什么？**
   - 提供高天花板（灵活扩展）和低地板（易于上手）的能力。
   - 支持短时记忆、长时记忆、流式处理、容错等生产级功能。

2. **随着模型改进，是否一切都会变成智能体？**
   - 模型性能提升后，简单工具调用循环可能适用于某些任务，但大多数企业任务仍需定制化工作流。
   - 智能体和工作流的结合仍是主流。

3. **OpenAI 的误解**
   - OpenAI 将“声明式 vs 非声明式”与“智能体 vs 工作流”混为一谈，忽略了可靠编排层的重要性。

## 结论
智能体框架的核心挑战是确保 LLM 在每一步获得正确上下文。LangGraph 作为编排框架，提供了灵活的底层控制和丰富的生产级功能，适用于各种形状和规模的智能体系统。</p>
        </li>
        <li>
          <h2><a href="https://blog.langchain.dev/customers-abu-dhabi-government/">TAMM AI Assistant: Transforming Government Services in Abu Dhabi with LangChain and LangGraph"</a></h2>
          <p># TAMM AI助手：阿布扎比政府服务的革新  

TAMM平台是阿布扎比政府的一站式服务平台，提供940多项服务，涵盖驾驶执照申请、罚款支付和个人文件检索等。2024年10月发布的TAMM 3.0引入了AI助手，通过LangChain和LangGraph技术彻底改变了服务交付方式。  

## 核心功能  
TAMM AI助手具备五大关键工作流：  
1. **服务查询与信息检索**：通过RAG管道精准回答用户问题。  
2. **用户特定数据交互**：根据用户历史提供个性化响应。  
3. **服务执行**：支持跨平台无缝完成服务操作。  
4. **通用知识与讨论**：利用大语言模型扩展问答范围。  
5. **支持流程**：包括“拍照并报告”功能，提升事件处理效率。  

## 技术亮点  
基于LangChain和LangGraph，TAMM AI助手采用多代理架构，确保灵活性和标准化，同时严格遵守政府标准。  

## 未来展望  
TAMM AI助手展现了DGE在数字转型中的全球领导地位，未来将继续优化公民体验，推动智能政府服务的发展。</p>
        </li>
  </ul>
<p></body>
</html></p>