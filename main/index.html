<p><!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>洗衣液价格比较</title>
  </p>
<style>
    body { font-family: Arial, sans-serif; margin: 20px; }
    .article { margin-bottom: 40px; }
    .title { font-size: 24px; margin-bottom: 10px; }
    .content { line-height: 1.6; }
  </style>
<p></head>
<body>
  </p>
<h1>价格比较</h1>
<ul>
        <li>
          <h2><a href="https://blog.langchain.dev/customers-webtoon/">How Webtoon Entertainment built agentic workflows with LangGraph to scale story understanding</a></h2>
          <p># Webtoon Entertainment 使用 LangGraph 构建叙事理解 AI

**Webtoon Entertainment** 是全球领先的数字娱乐平台，运营 **WEBTOON** 和 **Wattpad** 两大平台，以垂直滚动漫画格式闻名。公司通过将原创 IP 改编为影视、动画等内容，推动跨媒体内容生态发展。

为应对海量内容处理需求，Webtoon 开发了 **Webtoon Comprehension AI (WCAI)**，利用 **LangGraph** 的智能工作流技术，自动化理解角色、叙事和视觉/文本内容。WCAI 已部署于营销、翻译和推荐团队，用自然语言查询取代手动浏览，显著提升效率。

## 技术亮点
- **LangGraph** 提供模块化架构，支持动态工作流路由。
- 核心工作流包括：角色识别、说话人识别、叙事提取及业务洞察生成。
- 结合视觉语言模型（VLM）和领域专家知识，确保高质量输出。

## 为何选择 LangGraph？
1. **可控性与可靠性**：满足生产环境对透明性和结果可解释的需求。
2. **生产级部署**：LangSmith 提供强大的调试和追踪能力，优化性能。

## 成果与展望
WCAI 自动化处理大量 Webtoon 数据，减少团队 70% 手动工作量，并支持创意与策略聚焦。未来计划包括系统性评估、精细化人机交互控制及外部数据整合，进一步释放 Webtoon IP 潜力。</p>
        </li>
        <li>
          <h2><a href="https://blog.langchain.dev/langsmith-alerts/">Catch production failures early with LangSmith Alerts</a></h2>
          <p># LangSmith Alerts：提前捕获生产故障

为了帮助开发者提供更可靠的用户体验，LangSmith 推出了 **Alerts** 功能，专注于实时监控 LLM 应用和智能代理的运行状态。通过设置基于关键指标（如错误率、运行延迟、反馈评分）的告警机制，团队可以在问题影响用户之前快速响应。

## 为什么主动监控很重要？

LLM 应用面临两大主要挑战：
1. **外部服务依赖**：模型提供商、API、数据库等依赖的服务可能出现中断或延迟。
2. **质量与正确性**：提示、模型或输入的微小变化可能导致输出质量下降。

LangSmith 的告警功能通过用户反馈和在线评估提供早期预警，确保问题被及时发现。

## 功能概览

- 支持监控 **错误数量/率**、**平均延迟** 和 **平均反馈评分**。
- 提供灵活过滤器，聚焦特定运行子集（如按模型或工具调用）。
- 可自定义聚合窗口（5 或 15 分钟）和阈值。
- 集成 PagerDuty 或自定义 Webhook（如 Slack）通知。

## 未来计划

- 增加更多告警类型（如运行计数、Token 使用量）。
- 支持相对值告警（如延迟增加 25%）。
- 自定义时间窗口。

[立即开始配置告警](https://docs.smith.langchain.com/observability/how_to_guides/alerts?ref=blog.langchain.dev) 并加入 [LangChain Slack 社区](https://www.langchain.com/join-community?ref=blog.langchain.dev) 提供反馈！</p>
        </li>
        <li>
          <h2><a href="https://blog.langchain.dev/customers-trellix/">How Trellix cut log parsing time from days to minutes with LangGraph Studio and LangSmith</a></h2>
          <p># Trellix 使用 LangGraph 和 LangSmith 提升日志解析效率

Trellix 是一家领先的网络安全公司，通过开发内部应用 Sidekick，显著提升了客户请求处理效率。Sidekick 利用 LangSmith 和 LangGraph Studio 自动化日志解析和插件开发任务，将手动解析时间从数天缩短至几分钟。

## 核心问题
Trellix 面临客户请求积压和日志解析耗时的问题，传统方法需要开发者花费 2-3 天完成日志解析、编码集成和客户沟通，导致客户体验不佳。

## 解决方案
1. **LangGraph 的优势**  
   LangGraph 提供了模块化工具和低级抽象技术，支持通过子图调用和 Send API 构建高效的工作流，简化了复杂任务的开发。

2. **LangGraph Studio 的可视化能力**  
   工程团队通过 LangGraph Studio 将手动流程转化为自动化工作流，并为非技术人员提供清晰的 AI 决策逻辑展示，增强跨团队协作。

3. **LangSmith 的监控与优化**  
   使用 LangSmith 进行实验设计和性能监控，跟踪递归率等关键指标，确保数据驱动的决策，加速调试和优化。

## 影响与未来计划
- 日志解析时间从 **数天缩短至分钟级**，大幅提升效率。
- 加速客户请求解决，减少积压，提高满意度。
- 计划扩展 Sidekick 功能至外部合作伙伴，进一步推动 AI 在网络安全中的应用。

通过 LangSmith 和 LangGraph，Trellix 成功实现了运营效率提升，为未来创新奠定了基础。</p>
        </li>
        <li>
          <h2><a href="https://blog.langchain.dev/how-to-think-about-agent-frameworks/">How to think about agent frameworks</a></h2>
          <p>```markdown
本文探讨了构建可靠代理系统（agentic systems）的挑战及框架选择的关键问题。以下是核心内容总结：

1. **代理系统的难点**  
   构建可靠代理系统的核心在于确保语言模型（LLM）在每一步都能获得适当的上下文。这包括精确控制输入LLM的内容，以及生成相关上下文的步骤。

2. **代理与工作流的区别**  
   - **工作流**：通过预定义路径编排LLM和工具，流程更确定性。  
   - **代理**：LLM动态控制自身流程和工具使用，灵活性更高。  
   实际生产中，大多数系统是两者的结合。

3. **代理框架的现状**  
   大多数框架仅提供代理抽象，而非灵活的编排层。这种抽象虽然易于入门，但常会掩盖上下文控制的复杂性。

4. **LangGraph的特点**  
   LangGraph是一个兼具声明式和命令式API的编排框架，支持工作流、代理及其混合形式。它提供了短期记忆、长期记忆、人类介入、流式处理等功能，适合构建可靠的代理系统。

5. **常见问题讨论**  
   - **是否需要框架？** 如果应用不需要复杂的特性（如记忆、容错等），可以不依赖框架。  
   - **模型改进后是否会取代工作流？** 即使模型性能提升，工作流仍将在简单、高效的任务中占优，而混合模式仍是主流。

6. **对OpenAI观点的批评**  
   OpenAI将“声明式 vs 命令式”与“代理 vs 工作流”混淆，忽略了编排层的重要性。代理抽象虽易用，但限制了开发者对上下文的精确控制。

7. **未来展望**  
   随着模型能力增强，特定任务可能仅需简单的工具调用循环，但控制输入上下文的重要性不会减弱。混合形式的代理系统将继续主导生产环境。
```
```</p>
        </li>
        <li>
          <h2><a href="https://blog.langchain.dev/customers-abu-dhabi-government/">TAMM AI Assistant: Transforming Government Services in Abu Dhabi with LangChain and LangGraph"</a></h2>
          <p># TAMM AI助手：用LangChain和LangGraph革新阿布扎比政府服务

TAMM平台是阿布扎比政府的一站式服务平台，提供超过940项服务。2024年10月发布的TAMM 3.0引入了AI助手，彻底改变了服务交付方式。该助手基于LangChain和LangGraph构建，支持五项关键工作流程：  
1. **服务查询与信息检索**：通过RAG管道高效回答用户问题。  
2. **用户特定数据交互**：根据用户历史提供个性化服务。  
3. **服务执行**：跨平台无缝完成服务请求。  
4. **通用知识与讨论**：扩展至广泛主题的智能对话。  
5. **支持流**：如“拍照并报告”功能，简化事件处理。

TAMM AI助手通过多代理架构提升了灵活性和标准化，展示了阿布扎比在数字政府服务领域的全球领导地位，未来还将进一步推动数字化转型和用户体验优化。  

![TAMM AI助手架构](https://blog.langchain.dev/content/images/2025/04/1000354819.png)t/20250425/2f5d76ef7a626681b92a2252c2f63753.png?Expires=1777057309&OSSAccessKeyId=LTAI5tL97mBYzVcjkG1cUyin&Signature=AZFDxC84Cgx%2Bz%2BEKg0woI6enMoA%3D)</p>
        </li>
  </ul>
<p></body>
</html></p>