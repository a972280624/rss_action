<p><!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>洗衣液价格比较</title>
  </p>
<style>
    body { font-family: Arial, sans-serif; margin: 20px; }
    .article { margin-bottom: 40px; }
    .title { font-size: 24px; margin-bottom: 10px; }
    .content { line-height: 1.6; }
  </style>
<p></head>
<body>
  </p>
<h1>价格比较</h1>
<ul>
        <li>
          <h2><a href="https://blog.langchain.dev/customers-webtoon/">How Webtoon Entertainment built agentic workflows with LangGraph to scale story understanding</a></h2>
          <p># Webtoon Entertainment 使用 LangGraph 构建叙事理解 AI

**Webtoon Entertainment**（纳斯达克代码：WBTN）是全球数字娱乐公司，以垂直滚动漫画格式闻名，运营两大平台：**WEBTOON** 和 **Wattpad**，连接全球用户与多样化内容。其原创 IP 被改编为电影、电视剧和动画，成为跨媒体热门作品。

## Webtoon Comprehension AI (WCAI)
为了处理海量内容，Webtoon 开发了 **WCAI**，基于 **LangGraph** 的多智能体工作流系统，能够深度理解角色、叙事及视觉/文本上下文，支持营销、翻译和推荐团队。通过自然语言查询，WCAI 提供即时洞察、总结和角色亮点，减少手动操作需求。

### 核心技术
- 使用 **Vision-Language Models (VLMs)** 和智能体工作流。
- 基于 **LangGraph** 的模块化架构，支持动态路由和领域知识注入。
- 关键工作流包括：
  1. **角色识别**：提取角色信息并构建结构化档案。
  2. **说话人识别**：分析对话气泡并归因角色。
  3. **叙事提取**：生成情节摘要和情感分析。
  4. **业务洞察**：为不同团队提供定制化输出，如关键词和场景亮点。

### 为何选择 LangGraph？
1. **可控性**：满足生产环境中对透明性和可靠性的需求。
2. **生产就绪**：轻松部署 API 并集成到现有系统，借助 **LangSmith** 实现高效调试。

## 成果与未来
WCAI 自动化叙事理解，减少了 70% 的手动工作量，显著提升生产力。未来计划包括：
- 系统化评估新业务场景。
- 优化人机交互控制。
- 引入外部数据源增强分析能力。

通过 WCAI 和 LangGraph，Webtoon 正在引领叙事理解的规模化创新，赋能团队创造力，释放 IP 潜力。</p>
        </li>
        <li>
          <h2><a href="https://blog.langchain.dev/langsmith-alerts/">Catch production failures early with LangSmith Alerts</a></h2>
          <p># LangSmith Alerts：提前捕获生产故障

为了打造可靠的用户体验，LangSmith 推出了**实时告警功能**，帮助开发者在问题影响用户之前发现并解决。支持基于关键指标（如**错误率**、**运行延迟**、**反馈评分**）设置告警，适用于 LLM 应用和智能代理的监控。

## 为什么主动监控很重要？

1. **对外部服务的依赖**  
   LLM 应用通常依赖多个外部服务（如模型提供商、API、数据库等），这些服务的中断或延迟会直接影响用户体验。

2. **质量与正确性**  
   LLM 输出的质量可能因提示词、模型或输入的变化而波动，实时反馈评分告警可帮助快速识别质量下降。

## LangSmith 告警功能概述

- 支持的指标：
  1. 错误数量与错误率
  2. 平均延迟
  3. 平均反馈评分
- 可按模型、工具调用等筛选特定运行子集。
- 支持 5 或 15 分钟聚合窗口，并可通过 PagerDuty 或自定义 Webhook 集成到现有工作流。

## 未来计划

- 新增告警类型：运行计数、LLM Token 使用量。
- 支持相对值变化告警（如延迟激增 25%）。
- 自定义时间窗口告警。

[了解更多](https://docs.smith.langchain.com/observability/how_to_guides/alerts?ref=blog.langchain.dev)并加入 [LangChain Slack 社区](https://www.langchain.com/join-community?ref=blog.langchain.dev) 提供反馈！</p>
        </li>
        <li>
          <h2><a href="https://blog.langchain.dev/customers-trellix/">How Trellix cut log parsing time from days to minutes with LangGraph Studio and LangSmith</a></h2>
          <p># Trellix 使用 LangGraph 和 LangSmith 提升效率案例总结

Trellix 是一家领先的网络安全公司，致力于帮助企业应对网络攻击威胁。面对客户请求积压和日志解析耗时的挑战，Trellix 开发了内部应用 Sidekick，利用 **LangSmith** 和 **LangGraph**（包括 LangGraph Studio）实现任务自动化。

## 核心问题与解决方案
1. **问题：**
   - 客户请求积压严重，工程师需花费 2-3 天手动解析日志并开发集成。
   - 过长的处理时间导致客户体验差和支持效率低下。

2. **解决方案：**
   - 使用 LangGraph 和 LangSmith 构建 Sidekick 平台，自动解析日志和生成脚本。
   - 日志解析时间从几天缩短到几分钟，插件开发时间从多天减少到半天。
   - 利用 LangGraph 的模块化设计优化工作流，并通过 LangGraph Studio 提供可视化工具，帮助技术与非技术人员理解 AI 决策过程。

## 技术优势
- **LangGraph：** 提供低级工具和高级抽象功能，支持子图调用和模块化设计。
- **LangGraph Studio：** 可视化工作流，便于团队协作和向业务利益相关者展示。
- **LangSmith：** 通过实验和性能监控，持续优化 AI 模型表现。

## 成果与未来计划
- **成果：**
  - 工程师效率大幅提升，客户请求处理速度加快。
  - 通过数据驱动的方式提升 AI 性能和利益相关者信心。
- **未来计划：**
  - 将 Sidekick 能力扩展至外部合作伙伴。
  - 推广自动化解析和云连接器至所有客户。

## 结论
Trellix 借助 LangSmith、LangGraph 和 LangGraph Studio 成功解决了网络安全领域的运营难题，不仅提升了内部效率，还显著改善了客户满意度，为未来的 AI 驱动解决方案奠定了基础。</p>
        </li>
        <li>
          <h2><a href="https://blog.langchain.dev/how-to-think-about-agent-frameworks/">How to think about agent frameworks</a></h2>
          <p># 关于智能体框架的思考总结

本文探讨了构建可靠智能体系统的核心挑战及智能体框架的设计原则，重点分析了智能体与工作流的区别、声明式与命令式框架的优劣，以及如何选择合适的框架。

## 核心观点
1. **构建可靠智能体系统的难点**  
   确保大语言模型（LLM）在每一步都能获得适当的上下文。这包括精确控制输入内容和生成相关上下文的步骤。

2. **智能体系统的特点**  
   智能体系统由工作流和智能体组成，二者可以结合使用。工作流强调预定义路径，而智能体强调动态决策。

3. **现有智能体框架的局限性**  
   大多数智能体框架仅提供抽象层，而非灵活的编排工具。这种抽象虽然易于上手，但可能掩盖上下文控制的关键问题。

4. **LangGraph 的定位**  
   LangGraph 是一个兼具声明式和命令式 API 的编排框架，支持工作流、智能体及其混合形式。它提供了短/长期记忆、人类介入、容错等生产级功能。

## 智能体框架的关键维度
- **灵活性**：是否为灵活的编排层，还是仅提供智能体抽象。
- **声明式 vs 命令式**：是否通过声明式语法定义逻辑，或通过代码实现动态控制。
- **附加功能**：如多轮对话支持、流式传输、调试工具等。

## 常见问题解答
1. **框架的价值**  
   框架简化了开发流程，提供了上下文管理、持久化、容错等功能，尤其适合复杂场景。但对于简单应用，可能不需要完整框架。

2. **模型进步是否会减少对工作流的需求**  
   即使模型性能提升，仍需结合具体任务需求选择工作流或智能体。对于独特任务，定制化工作流仍然重要。

3. **OpenAI 的误解**  
   OpenAI 的观点混淆了“声明式 vs 命令式”、“工作流 vs 智能体”等不同维度，低估了编排层的重要性。

## 结论
- 构建可靠的智能体系统需要精确控制 LLM 的上下文。
- 工作流和智能体各有优势，应根据任务需求选择合适的形式。
- LangGraph 提供了一个灵活且功能丰富的编排框架，适合各种规模的智能体系统。

[查看智能体框架对比表](https://docs.google.com/spreadsheets/d/1B37VxTBuGLeTSPVWtz7UMsCdtXrqV5hCjWkbHN8tfAo/edit?usp=sharing)</p>
        </li>
        <li>
          <h2><a href="https://blog.langchain.dev/customers-abu-dhabi-government/">TAMM AI Assistant: Transforming Government Services in Abu Dhabi with LangChain and LangGraph"</a></h2>
          <p># TAMM AI助手：阿布扎比政府服务的革新  

TAMM平台是阿布扎比政府的一站式服务平台，提供940多项服务，涵盖公民、居民、访客和企业需求。2024年10月，TAMM 3.0发布，引入AI技术全面优化服务交付与用户体验。其核心功能包括：

1. **服务查询与信息检索**：通过RAG管道快速回答用户问题，如护照更新或驾驶执照申请要求。  
2. **用户数据个性化交互**：根据用户历史数据提供定制化服务，如有效文件或到期提醒。  
3. **服务执行**：跨平台无缝完成服务请求，确保统一体验。  
4. **通用知识问答**：支持广泛主题咨询，如旅游建议。  
5. **支持流**：新增“拍照并报告”功能，自动处理事件并提交相关部门。

基于LangChain和LangGraph，TAMM AI助手实现了高效、灵活的服务架构，树立了全球数字政府服务标杆。未来，TAMM将继续推动AI驱动的创新，提升公民参与体验。  

![TAMM AI助手架构](https://blog.langchain.dev/content/images/2025/04/1000354819.png)t/20250425/2f5d76ef7a626681b92a2252c2f63753.png?Expires=1777068119&OSSAccessKeyId=LTAI5tL97mBYzVcjkG1cUyin&Signature=1T4WB6w4TYsANB6f9fZFEs9rTro%3D)</p>
        </li>
  </ul>
<p></body>
</html></p>