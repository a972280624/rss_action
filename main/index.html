<p><!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Harmonic 投资代理案例</title>
  </p>
<style>
    body { font-family: Arial, sans-serif; margin: 20px; }
    .article { margin-bottom: 40px; }
    .title { font-size: 24px; margin-bottom: 10px; }
    .content { line-height: 1.6; }
  </style>
<p></head>
<body>
        <div class="article">
      <h3>How Webtoon Entertainment built agentic workflows with LangGraph to scale story understanding</h3>
      <a href=https://blog.langchain.dev/customers-webtoon/>Read more</a>
      <p># Webtoon Entertainment 使用 LangGraph 构建叙事理解 AI</p>
<p><strong>Webtoon Entertainment</strong>（纳斯达克代码：WBTN）是全球数字娱乐公司，以垂直滚动漫画格式闻名，旗下拥有 <strong>WEBTOON</strong> 和 <strong>Wattpad</strong> 两大平台，致力于连接全球用户与多样化的内容。</p>
<p>为提升对海量内容的理解能力，Webtoon 开发了 <strong>Webtoon Comprehension AI (WCAI)</strong>，基于 <strong>LangGraph</strong> 的多智能体工作流。WCAI 能够深度理解角色、情节和视觉/文本上下文，并已部署于营销、翻译和推荐团队，显著减少手动操作，提升效率。</p>
<h3 id="">核心功能</h3>
<ul>
<li><strong>角色识别</strong>：提取角色名称、角色关系及代表图像。</li>
<li><strong>说话人识别</strong>：通过视觉语言模型（VLM）分析对话气泡并归因到角色。</li>
<li><strong>叙事提取</strong>：生成结构化摘要，捕捉关键情节和情感节点。</li>
<li><strong>业务洞察</strong>：根据用户意图生成特定业务需求的洞察，如高点击率场景提取或关键词生成。</li>
</ul>
<h3 id="-1">技术优势</h3>
<p>WCAI 基于 LangGraph 的模块化架构，支持动态工作流路由，确保高质量和一致性。LangGraph 提供的可控性、可解释性和生产级部署能力，使其成为理想选择。</p>
<h3 id="-2">成果与未来</h3>
<p>WCAI 自动化处理显著减少了 70% 的手动工作量，赋能团队专注于创意和战略任务。未来计划包括系统评估、人机交互优化以及整合外部数据源，进一步提升叙事理解能力。</p>
<p>Webtoon 正通过 WCAI 和 LangGraph 推动叙事理解的规模化发展，释放 IP 潜力。</p>
    </div>
        <div class="article">
      <h3>Catch production failures early with LangSmith Alerts</h3>
      <a href=https://blog.langchain.dev/langsmith-alerts/>Read more</a>
      <p># LangSmith Alerts：提前捕获生产故障</p>
<p>可靠的应用程序是优质用户体验的基础，而提前发现故障则是关键。LangSmith 推出了 <strong>Alerts</strong> 功能，帮助开发者实时监控 LLM 应用和代理。现在支持基于 <strong>错误率</strong>、<strong>运行延迟</strong> 和 <strong>反馈评分</strong> 设置告警。</p>
<h2 id="-3">为什么主动监控很重要？</h2>
<p>LLM 应用面临两大挑战：</p>
<ol>
<li><strong>对外部服务的依赖</strong>：模型提供商、API、数据库等的中断或延迟会显著影响用户体验。</li>
<li><strong>输出质量和正确性</strong>：提示词、模型或输入的小变化可能导致结果不稳定。基于用户反馈或在线评估的告警可提供早期预警。</li>
</ol>
<h2 id="langsmith">LangSmith 告警功能概览</h2>
<p>支持以下指标：</p>
<ul>
<li>错误数量和比率</li>
<li>平均延迟</li>
<li>平均反馈评分</li>
</ul>
<p>通过过滤器（如模型类型、工具调用）精确定位问题，并设置聚合窗口（5 或 15 分钟）和阈值。告警可通过 PagerDuty 或自定义 Webhook 集成到现有工作流中。</p>
<p><a href="https://docs.smith.langchain.com/observability/how_to_guides/alerts?ref=blog.langchain.dev">立即开始配置告警</a></p>
<h2 id="-4">未来计划</h2>
<ul>
<li>新增告警类型：运行计数、LLM Token 使用量</li>
<li>相对值变化告警（如延迟增加 25%）</li>
<li>自定义时间窗口</li>
</ul>
<p>有建议？加入 <a href="https://www.langchain.com/join-community?ref=blog.langchain.dev">LangChain Slack 社区</a> 分享你的想法！</p>
    </div>
        <div class="article">
      <h3>How Trellix cut log parsing time from days to minutes with LangGraph Studio and LangSmith</h3>
      <a href=https://blog.langchain.dev/customers-trellix/>Read more</a>
      <p># Trellix 借助 LangGraph 和 LangSmith 提升效率</p>
<p><strong>背景</strong>:<br />
Trellix 是一家领先的网络安全公司，拥有 4 万多家客户。其专业服务团队面临客户请求积压和日志解析耗时的问题，传统方法需要开发者花费 2-3 天完成任务，导致客户体验不佳。</p>
<p><strong>解决方案</strong>:<br />
Trellix 开发了内部应用 Sidekick，利用 LangSmith 和 LangGraph（包括 LangGraph Studio）实现自动化流程，显著缩短日志解析时间至分钟级，并加速插件开发。</p>
<p><strong>技术优势</strong>:  </p>
<ol>
<li><strong>LangGraph</strong>: 提供模块化设计和低级工具支持，简化开发复杂性。</li>
<li><strong>LangGraph Studio</strong>: 可视化工作流，帮助技术与非技术利益相关者理解 AI 模型逻辑。</li>
<li><strong>LangSmith</strong>: 监控性能指标，优化架构设计，提升调试效率。</li>
</ol>
<p><strong>成果</strong>:  </p>
<ul>
<li>日志解析时间从天缩短到分钟。</li>
<li>客户请求处理速度加快，减少积压。</li>
<li>提升工程师效率和客户满意度。</li>
</ul>
<p><strong>未来计划</strong>:<br />
Trellix 计划将 Sidekick 推广至外部合作伙伴，进一步普及 AI 驱动的网络安全解决方案。  </p>
<p><strong>结论</strong>:<br />
通过 LangGraph 和 LangSmith，Trellix 成功解决了运营挑战，提升了内部效率和客户体验，为未来创新奠定了基础。</p>
    </div>
        <div class="article">
      <h3>How to think about agent frameworks</h3>
      <a href=https://blog.langchain.dev/how-to-think-about-agent-frameworks/>Read more</a>
      <p># 总结：如何思考代理框架</p>
<p>本文探讨了构建可靠代理系统的核心挑战和框架选择的关键维度。</p>
<ul>
<li><strong>核心难点</strong>：确保语言模型（LLM）在每一步都获得适当的上下文，包括精确控制输入内容和生成相关上下文的步骤。</li>
<li><strong>代理系统的组成</strong>：包含工作流、代理及两者的混合形式。大多数生产环境中的系统是二者的结合。</li>
<li><strong>框架分类</strong>：</li>
<li>工作流与代理：工作流更可预测，代理更灵活。</li>
<li>声明式与命令式：LangGraph 是部分声明式的编排框架。</li>
<li>多代理系统：代理间的通信对上下文传递至关重要。</li>
<li><strong>框架价值</strong>：提供短/长期记忆、人类干预、流式处理、调试和容错等功能，提升开发效率和系统可靠性。</li>
<li><strong>常见误区</strong>：OpenAI 的指南混淆了“声明式 vs 命令式”、“工作流 vs 代理”等概念，低估了编排框架的重要性。</li>
<li><strong>LangGraph 特点</strong>：作为编排框架，支持声明式和命令式 API，并提供高层代理抽象，适合从简单到复杂的各类应用。</li>
</ul>
<p>结论：代理框架的选择需根据具体需求权衡灵活性与可控性，而 LangGraph 提供了全面的功能支持，是最适合构建生产级代理系统的工具之一。</p>
    </div>
        <div class="article">
      <h3>TAMM AI Assistant: Transforming Government Services in Abu Dhabi with LangChain and LangGraph"</h3>
      <a href=https://blog.langchain.dev/customers-abu-dhabi-government/>Read more</a>
      <p># TAMM AI助手：阿布扎比政府服务的革新  </p>
<p>TAMM平台是阿布扎比政府的一站式服务中心，提供940多项服务，涵盖公民、居民、游客和企业。2024年10月，在GITEX全球大会上，TAMM 3.0版本发布，引入了基于LangChain和LangGraph的AI助手，彻底改变了政府服务体验。  </p>
<h2 id="-5">核心功能</h2>
<p>TAMM AI助手具备五大关键工作流：  </p>
<ol>
<li><strong>服务查询与信息检索</strong>：通过RAG管道快速响应用户问题，如护照续签或驾照申请所需文件。  </li>
<li><strong>用户特定数据交互</strong>：根据用户历史提供个性化服务，如有效文件或到期提醒。  </li>
<li><strong>服务执行</strong>：无缝完成跨平台服务请求，确保一致体验。  </li>
<li><strong>通用知识与讨论</strong>：支持广泛话题，如推荐露营地点。  </li>
<li><strong>支持流程</strong>：新增“拍照并报告”功能，自动提交事件报告并分配至相关部门。  </li>
</ol>
<h2 id="-6">技术亮点</h2>
<p>借助LangChain和LangGraph，TAMM实现了多代理架构，提升灵活性与标准化，同时确保严格的安全性和高效的数据处理能力。  </p>
<h2 id="-7">未来展望</h2>
<p>TAMM AI助手代表了公民参与的未来方向，持续推动数字政府服务的全球标杆建设。</p>
    </div>
</body>
</html></p>